# Justicia Clara - SimplificaciÃ³n de Textos Legales

Sistema para simplificar textos legales en espaÃ±ol a lenguaje claro, manteniendo el significado original.

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Instalar dependencias
pip install -r requirements.txt

# Si necesitas CPU-only PyTorch (opcional)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### 2. ConfiguraciÃ³n

Crea un archivo `.env` en la raÃ­z del proyecto:

```bash
# LLM Provider
MODEL_PROVIDER=ollama  # o "openai"

# OpenAI (si usas OpenAI)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# Ollama (si usas Ollama)
OLLAMA_MODEL=llama3
OLLAMA_BASE_URL=http://localhost:11434
```

### 3. Preparar Ollama (si usas Ollama)

```bash
# AsegÃºrate de que Ollama estÃ© corriendo
ollama serve

# Descargar modelo (si no lo tienes)
ollama pull llama3
```

### 4. Ejecutar la UI

```bash
cd justicia-clara
streamlit run ui.py
```

La aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501`

## ğŸ“‹ Uso

### Interfaz Web (Streamlit)

1. Abre la aplicaciÃ³n en tu navegador
2. Usa la pestaÃ±a **PDF** para subir un PDF
3. O usa la pestaÃ±a **Texto** para pegar texto directamente
4. Haz clic en "Procesar"
5. Revisa los resultados:
   - Estado de validaciÃ³n (Aprobado/Rechazado)
   - Similitud semÃ¡ntica
   - Texto simplificado
   - Detalles de validaciÃ³n

### CLI (prÃ³ximamente)

```bash
python cli.py data/raw/sample.txt
```

## ğŸ§ª Archivo de Prueba

Hay un archivo de ejemplo en `data/raw/sample.txt` que puedes usar para probar el sistema.

## ğŸ“ Estructura del Proyecto

```
justicia-clara/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schema.py       # Modelos Pydantic
â”‚   â”œâ”€â”€ llm.py          # IntegraciÃ³n LLM (Ollama/OpenAI)
â”‚   â”œâ”€â”€ checks.py       # Validaciones determinÃ­sticas
â”‚   â”œâ”€â”€ semantic.py     # Similitud semÃ¡ntica
â”‚   â”œâ”€â”€ ocr.py          # OCR con docTR (opcional)
â”‚   â””â”€â”€ pipeline.py     # OrquestaciÃ³n principal
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Archivos de entrada
â”‚   â””â”€â”€ outputs/        # Resultados JSON
â”œâ”€â”€ cli.py              # CLI (en desarrollo)
â”œâ”€â”€ ui.py               # Interfaz Streamlit
â””â”€â”€ requirements.txt    # Dependencias
```

## ğŸ” Validaciones

El sistema valida que la simplificaciÃ³n:
- âœ… Mantiene los mismos importes
- âœ… Mantiene las mismas fechas
- âœ… Mantiene los mismos artÃ­culos legales
- âœ… No invierte negaciones
- âœ… Tiene similitud semÃ¡ntica â‰¥ 0.80
- âœ… Pasa la evaluaciÃ³n del "juez" LLM

## ğŸ› ï¸ Troubleshooting

### Error: "Import doctr could not be resolved"
- Es solo una advertencia del IDE. El cÃ³digo funciona correctamente.

### Error: "Ollama connection failed"
- AsegÃºrate de que `ollama serve` estÃ© corriendo
- Verifica que el modelo estÃ© descargado: `ollama list`

### Error: "OpenAI API key not found"
- Crea el archivo `.env` con tu `OPENAI_API_KEY`
- O cambia `MODEL_PROVIDER=ollama` en `.env`

### OCR no funciona
- AsegÃºrate de tener `python-doctr[torch]` instalado
- Los modelos de docTR se descargan automÃ¡ticamente la primera vez

## ğŸ“ Notas

- El primer modelo (simplificaciÃ³n) usa **OpenAI** por defecto
- El segundo modelo (juez) usa **Ollama** por defecto
- Puedes cambiar los proveedores en `app/pipeline.py` o vÃ­a variables de entorno

